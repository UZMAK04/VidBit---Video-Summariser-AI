{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UZMAK04/VidBit---Video-Summariser-AI/blob/main/video_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWSwx0tDKACo",
        "outputId": "9544019d-e0f7-4d27-b0b3-a8f1b0280afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,087 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,795 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,948 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,758 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,102 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,266 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,569 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,414 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [113 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [38.4 kB]\n",
            "Fetched 31.5 MB in 6s (5,180 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 1: Install System Dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtZQUS5Xvpq0",
        "outputId": "90066beb-9a99-468c-dd37-409c69e218cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting torch==2.3.1\n",
            "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting scenedetect\n",
            "  Downloading scenedetect-0.6.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.14)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.116.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.6.30-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m299.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch==2.3.1)\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.33.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.2)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from scenedetect) (8.2.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from scenedetect) (4.3.8)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2025.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m272.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m305.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m204.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m266.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m249.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m274.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m280.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m277.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m265.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m269.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m258.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m330.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m243.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m383.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m277.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scenedetect-0.6.6-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m357.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m399.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.116.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m353.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading yt_dlp-2025.6.30-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m243.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m207.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m277.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m240.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m268.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m277.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m346.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp, triton, scenedetect, pyngrok, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, ctranslate2, av, nvidia-cusolver-cu12, nvidia-cudnn-cu12, coloredlogs, torch, onnxruntime, fastapi, transformers, torchvision, faster-whisper, sentence-transformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.14\n",
            "    Uninstalling fastapi-0.115.14:\n",
            "      Successfully uninstalled fastapi-0.115.14\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 4.1.0\n",
            "    Uninstalling sentence-transformers-4.1.0:\n",
            "      Successfully uninstalled sentence-transformers-4.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-15.0.0 coloredlogs-15.0.1 ctranslate2-4.6.0 fastapi-0.116.0 faster-whisper-1.1.1 humanfriendly-10.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.22.0 pyngrok-7.2.11 scenedetect-0.6.6 sentence-transformers-5.0.0 torch-2.3.1 torchvision-0.18.1 transformers-4.53.1 triton-2.3.1 yt-dlp-2025.6.30\n"
          ]
        }
      ],
      "source": [
        "!pip cache purge\n",
        "!pip install --no-cache-dir moviepy==1.0.3 faster-whisper torch==2.3.1 torchvision scenedetect librosa numpy sentence-transformers tqdm fastapi uvicorn pyngrok nest-asyncio yt-dlp transformers --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-2OuRr4KZXk",
        "outputId": "8e6c933d-3336-4df1-86c2-283991073846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube Video URL: https://www.youtube.com/watch?v=zlUpTlaxAKI\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=zlUpTlaxAKI\n",
            "[youtube] zlUpTlaxAKI: Downloading webpage\n",
            "[youtube] zlUpTlaxAKI: Downloading tv client config\n",
            "[youtube] zlUpTlaxAKI: Downloading tv player API JSON\n",
            "[youtube] zlUpTlaxAKI: Downloading ios player API JSON\n",
            "[youtube] zlUpTlaxAKI: Downloading m3u8 information\n",
            "[info] zlUpTlaxAKI: Downloading 1 format(s): 248+251\n",
            "[download] Destination: Introduction to NLP _ NLP Lecture 1 _ End to End NLP Course.f248.webm\n",
            "[download] 100% of  109.74MiB in 00:00:07 at 14.25MiB/s  \n",
            "[download] Destination: Introduction to NLP _ NLP Lecture 1 _ End to End NLP Course.f251.webm\n",
            "[download] 100% of   37.83MiB in 00:00:02 at 15.20MiB/s  \n",
            "[Merger] Merging formats into \"Introduction to NLP _ NLP Lecture 1 _ End to End NLP Course.mp4\"\n",
            "Deleting original file Introduction to NLP _ NLP Lecture 1 _ End to End NLP Course.f251.webm (pass -k to keep)\n",
            "Deleting original file Introduction to NLP _ NLP Lecture 1 _ End to End NLP Course.f248.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3\n",
        "\n",
        "import yt_dlp\n",
        "import re\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def extract_video_id(url):\n",
        "    parsed_url = urlparse(url)\n",
        "\n",
        "    # Handle shortened URLs (youtu.be)\n",
        "    if parsed_url.hostname in ['youtu.be']:\n",
        "        return parsed_url.path.lstrip('/')\n",
        "\n",
        "    # Handle regular YouTube URLs\n",
        "    if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
        "        if parsed_url.path == '/watch':\n",
        "            return parse_qs(parsed_url.query).get('v', [None])[0]\n",
        "        elif parsed_url.path.startswith('/embed/'):\n",
        "            return parsed_url.path.split('/')[2]\n",
        "        elif parsed_url.path.startswith('/v/'):\n",
        "            return parsed_url.path.split('/')[2]\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_video_info(video_id):\n",
        "    API_KEY = \"AIzaSyBvjWtjLyuqxYpyYtKQQVnxXgNVEwH3qa0\"\n",
        "\n",
        "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "    request = youtube.videos().list(\n",
        "        part='snippet,statistics,contentDetails',\n",
        "        id=video_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    video = response['items'][0]\n",
        "    snippet = video['snippet']\n",
        "    title = snippet['title']\n",
        "    return title\n",
        "\n",
        "def download_video(url, output_path='video.mp4'):\n",
        "    ydl_opts = {\n",
        "        # Force H.264 video + m4a audio\n",
        "        'format': 'bestvideo+bestaudio/best',\n",
        "        'outtmpl': output_path.rsplit('.', 1)[0] + '.%(ext)s',\n",
        "        'merge_output_format': 'mp4',\n",
        "        'quiet': False,\n",
        "        'prefer_ffmpeg': True,\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([url])\n",
        "            return output_path.rsplit('.', 1)[0] + '.mp4'\n",
        "        except Exception as e:\n",
        "            print(f\"[✗] Failed to download video: {e}\")\n",
        "            return None\n",
        "\n",
        "# --- Test ---\n",
        "url = input(\"Enter the YouTube Video URL: \")\n",
        "video_id = extract_video_id(url)\n",
        "\n",
        "if video_id:\n",
        "    title = get_video_info(video_id)\n",
        "    sanitized_title = re.sub(r'[\\\\/*?:\"<>|]', '_', title)  # Clean filename\n",
        "    output_path = sanitized_title + '.mp4'\n",
        "    video_path = download_video(url, output_path=output_path)\n",
        "else:\n",
        "    print(\"[✗] Invalid YouTube URL.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "b032b1bae0bf4434a33ec1b4996f2b8f",
            "640d704fac38475bb8e5e0b9a916d846",
            "78e6eec7244f47f68293bb952e188069",
            "57c58b95b3cf4c81a21359b6216c52fa",
            "7e80c782ff874dfbb0e317feac9bd97c",
            "1185be52a9cd4fdaaace3bd360dc20a9",
            "f5da46a2817549738cdb3037c77589c9",
            "9669f660a7254baa864d3beb9fe92e0b",
            "f7fd6b6f6b264846b2b5a77326414554",
            "39b9722c0dfc4bc299406fa0542dbf71",
            "f3f605f0e1654c8d9980beb989e201e8"
          ]
        },
        "id": "I6-vPHOcKdCv",
        "outputId": "c865c364-4ef1-4916-fa11-59392b7f5fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted to: audio.wav\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transcribing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b032b1bae0bf4434a33ec1b4996f2b8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription completed. Hello guys, my name is Nitesh and you are welcome to my YouTube channel  So as it was decided, from today we are going to start our natural language processing course  And today in this first lecture, I will talk about introduction to NLP  Why is the entire lecture on introduction? It's a very simple thing  NLP is a difficult topic and I believe that if you are going to read any difficult topic  Before approaching it, you should take an overview  You can see the important information in the left and right center  And after that, cover the difficult topics  That is why I have decided in detail that I will give you a good introduction of NLP  What will we read in this video?  We will start with the most important question that is what is NLP?  And why do we need NLP?  Then we will see what kind of applications NLP is being used in today's date  And then we will see what are some common NLP tasks  After that, I will cover one more topic where I will discuss  What kind of approaches have been used till date to make these NLP applications  And lastly, we will see one more very important topic  What are the biggest challenges in today's date in front of NLP that have stopped NLP?  So after reading all this, I think you will have an opinion form about NLP  Which will help you a lot in the future videos  So I have two requests from you  First request is that please watch the video end to end if you are serious about this course  And second request is that I will give you an assignment at the end of this video  I will give you an assignment at the end of every video at least  But you will also get an assignment at the end of this video  You complete that assignment  So now let's start the video  So guys, let's start with the first topic  First of all, we will discuss what is NLP and what is its need  So I have picked this definition from Wikipedia  So I am assuming that it is correct  Let's read it out once because I found this definition to be correct  Natural language processing is a subfield of linguistics, computer science and artificial intelligence  Concerned with the interactions between computers and human language  In particular, how to program computers to process and analyze large amounts of natural language data  So if you see this diagram on the right side, you will see that NLP is a field that is made up of three fields  The first field is human language, which you call linguistics  Second is computer science, which we are all aware of  And third is artificial intelligence  These three are made up of NLP  And the most important goal of NLP is to teach machines natural language  The idea is that not only machines can understand natural language  But they can also communicate in it  When we say something, they understand it  And when they also say something, it is in the natural language  So that is the whole idea  This field is quite new  Work on this has started in the last 50 years  And now in the last 10 years, there has been a lot of growth  Especially since deep learning has come, this field has started to bloom more  Now the question is this, why is this field important?  We need to understand the importance of NLP  We will see that in the next slide  Where we will discuss the need for NLP  To understand this need, it is important to understand what natural language is  So again, I have taken out a definition of natural language from Wikipedia  I will quickly show you  So the definition is  In neuropsychology, linguistics and philosophy of language  A natural language or ordinary language  Is any language that has evolved naturally in humans  Through the use and repetition without conscious planning or premeditation  Natural language can take different forms  It can be speech or sign  They are distinguished from constructed and formal language  Such as those used to program computers or to study logic  So what is natural language?  According to this definition  Humans have been evolving for many years  So if we come up with a way to communicate with each other  And improve it over the years  Then eventually it becomes a language  You can speak through speech or through signs  As you must have seen on some news channels  You tell the news through sign language  And this natural language is different from constructed languages  Such as our programming languages  It is very different from these  So why did I tell you this definition of natural language?  Because I want to explain to you why NLP is needed  Now I will use a small story to explain to you  Why NLP is important  So if you read a little bit of human history  Or read a little bit of human evolution  Then you would notice  That in the beginning, millions of years ago  Our ancestors used to live in the jungle like other animals  And used to spend a very normal animal life  But fast forward a million years  We have evolved a lot  Today we are going into space  Whereas if you look at other animals  They are still doing the same work  So the question is  What did we do differently  That we went so far  So if you ask me  One of the most important factors  Which I feel is  The first factor is communication and language  Whatever we achieved  There was a big factor behind it  That we were able to talk to each other  We were able to explain our ideas to each other  Books came  And a lot of teachers came  And they passed on a lot of things in the next generation  We read things from the previous generation  And moved forward  So that is how our evolution has happened  So language and communication  This is the thing  Which has put us on the path of growth  Now if you ask me  What is the second factor which has moved us a lot  So I would say the second factor is machines  If you look at 300-400 years ago  Industrial revolution came  And after that our evolution  It has completely escalated  It has started to grow very fast  We have brought machines in every domain  And today if you look  The machines and the internet  How much we have moved forward  Now I feel  A third revolution  A third factor is still to come  And that is  When we can talk to machines  Just like we do with our fellow human beings  Even today if you talk about machines  It is not that easy to talk to them  When machines were there in the beginning  To run them  You used to use mechanical things  Like levers and all  Then when electronic machines came  You started using switches  Now when the era of computer science came  You started to program them  But not everyone is able to program  There are very specialized computer science engineers  Who program these machines  Can a normal person still run the machine so well?  No  Even today if you want to run your smartphone  You have to point with your hands  Now imagine a world  Where you can talk to any machine  Absolutely easily  Just like you  Are talking to a human being  Then imagine how fast  Our progress will be  Imagine you are standing in an ATM machine  And a good person comes there to withdraw money  And he doesn't understand  What is the interface  He can simply ask him  And the machine is telling him  To press the button  And he is explaining everything  Like a human being is talking  So that is the next frontier  The next frontier of evolution  Is that we should talk  With our machines  Just like we talk with  Any other human being  And then you will see  That we will be able to evolve  Now it's not like there is no growth  Or we are not able to talk with machines  Take the example of Google Now  Take the example of Siri  Take the example of Cortana  These are some examples  Where we are trying to talk with machines  Where this is possible  But that is the dream  That we have to evolve more  So NLP is one of those things  Which when it will come  In our life  It will revolutionize  The entire humanity  So that is why NLP is  Very very important  And today every big company  Is investing money on NLP  Is making efforts on NLP  That we should become the first company  To take NLP forward  Now next I will tell you  Some applications  Which we are already using  For NLP  So guys now I will discuss two things with you  First some real world applications  Which already  Companies are putting in their product  And giving it to customers  And second I will tell you  About some common NLP tasks  If you want to become an NLP engineer  Then these are some 10-12 tasks  Which you can perform  And make many types of NLP applications  So these are like some common tasks  Which every NLP engineer should get  So let's start with some  Real world applications  Now applications are very simple  You might have seen  Chatbots or CD  Or Cortana  These are all examples of NLP applications  But I will tell you some different types of examples  Which will help you develop  Your perspective  For me personally  An NLP application  Kind of inspires  And seems very intriguing  Those are contextual  Advertisements  In the earlier world  Like if you go 20-25 years ago  Then I remember  When we used to watch matches on TV  Then the whole of India  Used to be shown the same advertisements  The company's assumption was  To show it to everyone  But today  Since we have NLP  We can process  How people behave  How their personality is  So we can actually  Run targeted advertisements  So if you noticed  Depending on your Facebook profile  Or Instagram profile  You can see different ads  From your friends  The company analyzes  Your profile, posts, comments  And then decides on the basis  That this person is very interested in sports  Or this person is very interested in cosmetics  And you can see targeted ads  Of those same things  In fact, if I tell you the truth  I feel like we are being tracked  Like if I chat a lot  On WhatsApp  On a topic  And if I use another application  Then I can see ads  About the topic I was chatting with my friend  Sometimes my phone is  Next to me  And I am talking about something  And as soon as I opened the phone  I can see ads about that  So the science behind all these things  That is contextual advertisements  And that is powered  Through NLP  The next one is  Email clients  If you have used Gmail  You must have noticed that there is spam filtering  If your email  Is spam  It automatically goes to the spam folder  And normal emails  Come to your normal folder  In fact, there are some new features  Like smart reply  So if you get an email  Then you get a suggestion  Of smart replies  And that suggestion is based on  What is the content of your email  So this is the second application  The third application is social media  One of the challenging tasks  Is removing adult content  So if you think about it  If you are making a social media platform  Then there is a big challenge  Because your platform is scaling  In crores of users  So in crores of users there can be  People who put such content on your platform  Which is not right for everyone  Like adult content  So how to filter that  Or if someone is saying very negative  Or spreading hate speech  Then how to block such things  All this is done through NLP  One more thing on social media  Is opinion mining  So if you take the example of twitter  So if a lot of people  Are talking about a topic  Then what twitter does  Is it picks up their opinion  And creates a sentiment  And uses it according to their knowledge  I gave an example of this  On my channel  Depending on the tweet  About the election  Twitter already knows  Which leader will win the election  Because  From the content of the tweet  Which leader is being supported  So these are all applications  The next one is search engines  Google  In the last 10-15 years  Google has evolved a lot  And there are a lot of new features  And that has become possible  Because of NLP  I can tell you a small feature  If you ask a question of general knowledge  Like what is the capital of Srilanka  Let's say  You don't need to go inside the website  And find out  What is the capital of Srilanka  Google will fetch that information for you  And show it in one line  So such small changes  Which happen in search engine  Are also NLP powered  In fact the functionality of search engine  Also uses a lot of NLP  Internally  One more example is chatbots  As I told you  Let's say  You are ordering food on Swiggy  And you don't like anything  As soon as you go on chat  There is a chatbot  And it talks like  A customer executive  So it  Made Swiggy very easy  Because on the scale  On which Swiggy is working  Customers have to handle together  It is not possible to have so many customer executives  So the chatbot  Tries at the initial level  To solve that problem  And if it doesn't work  Then it reroutes us to the customer executive  So again chatbots are very important  And that's it  There are many more examples  And I would actually  Ask you to think about this  You sit and think  That you use so many products  And what NLP is being used  It's a good thinking exercise  So now  I will discuss with you  Some common NLP tasks  Since we have to become an NLP engineer  We have to learn NLP  So there are some common tasks  Which you use to make such applications  So I have around 10 tasks  I will discuss with you one by one  The first common task  Is text or  Document classification  So suppose you have a big  Text and you  Have to put it in a particular category  One example could be  That you have a news  Full text  And you have to assign it a category  Like sports  Or entertainment or politics  You can do it very easily  Using text or document classification  The second task  Is sentiment analysis  This is also used a lot today  In e-commerce  Or social media  You read reviews  And you extract  Emotions from people's reviews  About what they are feeling  About a product or a movie  So companies use this a lot  Let's say I have a product  Which has 1 crore reviews  Now if I am asked to read  One review  I will have to waste  A lot of human hours  It will take a lot of time  To find out people's sentiment  It is very easy to make  An NLP application  In which you feed  All the 1 crore reviews  And it will tell you a percentage  That 80% of people are feeling positive  About your product  So this can save you a lot of money  If you are a big company owner  Next is  Information retrieval  As you can see on your screen  If you have a text  And you have to extract entities  Like date  Or person's name  Or product's name  Or event's name  If you want to extract  This comes under information retrieval  I gave you an example of a search engine  Search engines internally  Use information retrieval  In the future  We will cover a topic  Which will be named entity recognition  Where we will do exactly this  The next one is  Parts of speech tagging  This is a very important  Text preprocessing step  Where you  Assign every word  To a part of speech  Whether it is noun, verb or adjective  Why does it work?  Because if you are making a chatbot  Or a question answering system  Then there you should  Understand word by word  What the sentence is saying  This part of speech tagging  Helps a lot  And that is why this is a very important  Text preprocessing step  The next task is  Language detection and machine translation  If you have ever used Google translate  Then you would know  That it is such a powerful application  Where you can say anything  In any language  And translate it in any other language  Internally it is an NLP task  Where you are first of all  Detecting the language  And then  Based on the output  Which language you want  You translate it in that language  So here deep learning is used  In the future when we read it in more detail  You will know but again  This is a very very important task  Next is conversational agents  Like I gave you the example of Swiggy  This is kind of a chatbot  But there are two types of chatbots  One is text based  One is speech based  Like Siri is speech based  And the Swiggy you are using  Is text based  So again it is  A very very important  NLP application  Next one is very interesting  It is called knowledge graph  And QA system  If you have a big database  Of things  Then you can logically connect  Its entities to each other  And make a knowledge graph  After making it  You can translate it  Into a question answering system  Google actually uses this  Google's knowledge graph is  The biggest in the world  And they had a big database  Of things  They connected important entities  To each other  And made a big knowledge graph  Because of which  If you do queries like this  Who is the Prime Minister of Japan  So this is again  A very very important and  A little advanced level of NLP  Next is  Text summarization  This is a very interesting task  I read about this  When I found out about  InShots news application  So they used this internally  I don't know exactly  But I think they used this  If they have a full fledged article  Then you can summarize  You can give a small form  InShots also does this  That it gives you a news summary  In 60 words  Of every news  So again it is a NLP application  Which you are going to see in the future  The next one is  Topic modeling  This is also a very interesting task  What happens here is  If you have a big text  Then you can extract  The abstract topics  You can extract that information  Like if you have a big text  About cricket  Then you can read it  And extract this information  That the text is  About cricket  Is it about IPL, is it about Sachin  So you use this  In many different places  And here  Internally you use a machine learning algorithm  Which we call  LTA  So again we will cover this  In detail  I am going to do an entire  Lecture on topic modeling  So you will understand better  After that  There is text generation  I guess you have used this a lot  That in today's date  The keyboards you have  When you type  It automatically  On the basis of your previous typing behavior  Predicts what your next word should be  And we all know  How useful it is  While chatting with someone  Next is  Spell checking and grammar correction  So if you have used a tool like Grammarly  Then  What it does is  If there is a typo in your sentence formation  Or if you have done grammatical errors  Then it will quickly highlight it  So that you can improve it  So this is also an application  The second  Last one is  Text parsing  As you can see on the screen  You have a sentence  And you are breaking it down  Grammatically  So that you can explain to the machine  What the meaning of that sentence is  What it means  So again in making chatbots  Text parsing is an important  Pre-processing step  We will discuss this in the future  And the last one is speech to text  Where you make conversational agents  Like Siri and all  And  What happens is  You basically say something  And you convert it into text  And then you try to understand the text  And then there is a reverse process  You generate the results  And then you convert it back into speech  So this is also an important aspect  In today's date  Whenever you want to talk to the machine  And you don't want to type  So you use this type of technology  So this is  10-12 important  NLP tasks  In the future when you become an NLP engineer  And work in a company  So most likely you will work  On one or two of these  It is not possible to work on all of them  But more or less you will work  On these 10-12 things  More than this you may not have to  Study in NLP  Now you must be thinking  How all these things are made  So next I am going to explain  That in today's date  All the things that we have made in NLP  How they were made  What approaches we used  In making those things  We will discuss that next  So before discussing the approaches  I will just give you a disclaimer  That it is possible that  Whatever I tell you in this section  You didn't understand it completely  Because you will read all these things  But to take an overview  It is necessary  So you have to just understand  The core idea  So we are discussing  Whatever we have achieved  In the field of NLP  How we achieved it  What techniques we used  To achieve  Those applications  To build those applications  So 3 different approaches  That we used  I will show you  The first one is called heuristic methods  Second is  Machine learning based models  And the third one is  Deep learning based models  NLP started in 1950s  And around 90s  Almost 40 years  Heuristic methods were used  I will tell you what heuristic methods are  From 90s  The era of machine learning started  And from around 2010  The era of deep learning started  Which is still going on  So these 3 methods are still used  And they have their own impact  We will discuss them one by one  First of all  Let's discuss heuristic approaches  So let's go behind the word  What is heuristic  So you can see  If you see the meaning of heuristic  It is written here  A heuristic technique is any approach  To problem solving  Or self discovery  That employs a practical method  That is not guaranteed  To be optimal, perfect  Or rational, but is nevertheless  Sufficient for reaching an immediate  Short term goal or approximation  So in short  You can say  Heuristic approaches  Means to solve a problem  Means  You had to solve a problem  Mostly  NLP practitioners  Created rule-based approaches  I will give you some examples  Let's say you have to create  A sentiment analysis app  Where you will find  A sentiment of a text  Is it positive or negative  A rule-based approach  Is very simple  Count the number of positive words  In that text  And the number of negative words  So you can put  Such approaches under  Heuristic approach  Now many different  Types of heuristic approaches  Came in the last 50-60 years  I will give you three examples  Of the most famous and used  Approaches  Apart from this there are many more  Which we will discuss further  The first is regular expressions  If you have coded in python  Then you might know that  For that matter in all programming languages  There is a feature of regular expression  So what is regular expression  You can  Form a text  And dig a pattern text  Into another text  I will give you an example  When we will scrape text from any website  I will get HTML tags  I don't want those HTML tags  Now HTML tags are of different types  What I have to do  Is remove all HTML tags  I can do this very easily  With regular expressions  Or you can take another example  That  In a whole paragraph  I have to find salutations  I have to find Mr., Mrs.,  Master, doctor, Ph.D  So to find this kind of  Pattern  I can use regular expressions  So the initial approaches  Of solving NLP problems  In that regular expression  Was a very important tool  Which NLP practitioners  Used a lot  In this course  We will discuss in at least one section  How regular expressions are used  In NLP  Apart from this  Another very famous approach  Was wordnet  What is wordnet  Wordnet is basically a lexical dictionary  So in a normal dictionary  What do you get  A word, its meaning  Its synonyms, its antonyms  A lexical dictionary  Like wordnet  What you do in this  The relationships of a word  With other words  You store them in a very organized way  I will give you one example  Like run  And jog  The relationship between these two  Is similar  Then shoes and run  The relationship is that while running  You use shoes  So all these mappings  Were already made  And stored in this dictionary  So that if you want to make  Any kind of NLP application  Like translation  Or parts of speech tagging  Or any complex NLP application  There this wordnet  Will help you a lot  So there is a wordnet  In the NLP library  During this course  But at this point  The third one is  Open mind common sense  This is a kind of  Community  Where  All the facts  In the language  All the facts  Were stored  And it was an open source  That anyone in the world  Can contribute  The common facts  In the English language  That you are storing  So that it becomes a big database  Of common facts  So that when you make NLP systems  You can look at that database  And retrieve your information  So this is how it used to work  I have given you 2-3 examples  If you read some more  You will understand better  Now the question is  What is the advantage of heuristic approaches  The biggest advantage is  These are quick approaches  You get the answers  As soon as possible  And it is very accurate  There are less chances of errors  Because you have made rules  By making a person sit  So it is very less to fail  Now one more question  In today's scenario  Are heuristic approaches used  The answer is yes  In the future when we will see machine learning  In the NLP domain  There you will realize  That we will take help  Of heuristic approaches many times  So even today it is needed  And it is used  Now let's move on to the second approach  The second approach is machine learning  When the revolution of machine learning  Came in the 90s  It impacted NLP  The way we work with other types of data  In machine learning  Similarly you work with textual data  So first of all let's discuss  What is the big advantage  Of machine learning approaches  What was the advantage of heuristic approaches  The advantage was very simple  And very impactful  The advantage was  You make rules in heuristic approaches  Now there are some open-ended problems  Where making rules is not that possible  For a human being  Because there are too many rules  The problem is very open-ended  So in that situation  Machine learning approaches were useful  Because the rules in machine learning  Are made by your algorithm  Internally  The relationship between input and output  Is decided by looking at the data  And not by making a general rule  So that's why  Machine learning  The open-ended problems  In NLP  Were very useful in solving them  And slowly it became the go-to approach  To solve NLP problems  Heuristic approaches are used  But machine learning approaches  Are used in more powerful and wide variety  Of problems  Now you can ask  What is the entire workflow  How do you solve an NLP problem  It's quite similar  What you have to do is  Convert textual data into a number  Which is called text vectorization  Then you give that number  In a machine learning algorithm  And then you evaluate  The output  And that's it  The typical machine learning  Is done on normal data  In the same way  You do it on textual data  In fact you may have used  This type of flow  Maybe you have made a spam filter  Or you have done some other projects  Where machine learning is working on textual data  Now you can ask  Which algorithms should we read  So the most used algorithms  Let me tell you their names  First is Naive based  Probability based algorithm  Which gives very good results on textual data  Second is Logistic regression  Again a classification algorithm  Which gives you very good results  Third is SVM  Universally powerful algorithm  Third is LDA  LDA is used for a particular task  Called topic modeling  In which it is used  And the last one is hidden Markov models  Like POS tagging  Which I told you  Parts of speech tagging  Hidden Markov models can be used  So these 4-5 algorithms are the most used  So this was the machine learning  Approach  Now let's discuss deep learning  Approaches  So again the first question is  What is the advantage  Of deep learning  Over machine learning  That deep learning is used  So the first question is  What is the big advantage  There are two big advantages  Of deep learning based approaches  Over machine learning approaches  Let me tell you one by one  The first advantage is  In machine learning approaches  We convert textual data into numbers  And when we convert it into numbers  Most of the times  The sequential information  Of the text gets loosed  Machine learning algorithms  Are designed in such a way  That they don't care  About the sequential information  Which is present  Inside the text  But deep learning based models  Use this sequential information  Which means  Sentence formation  Is left to right in English  This is my house  So this sequence matters  You can't write like this  So retaining this sequential information  Deep learning has a big advantage  Because of which  The results are very good  Second  The biggest advantage of deep learning  Is that  The feature generation  Automatically models your deep learning  Whereas in machine learning  You have to make it yourself  According to your understanding  So this is also a big advantage  Now if you ask  Which architectures are used the most  In deep learning  I would say  Not the most used  But the first used was RNN  Recurrent Neural Network  Which gives very good results on sequential data  Be it textual data or time series data  It gives you very good results  The only problem is  If you provide  A very long sentence  Then  The context inside it  Can't be retained  Then LSTM came  Long short term memory  Its speciality is  That it can retain the context of big sentences  Its memory factor  Was better than RNN  So in today's date  Most NLP applications  In deep learning are based on LSTM  The third architecture is  CRU  Gated Recurrent Unit  This is used a lot for text generation  Then there is CNN  CNN is actually  Mainly used for image classification  Etc  But in some certain NLP applications  You will see that CNN is also used  Like text classification  After that  Transformers came in 2015  And after that  Things got revolutionized  The speciality of Transformers is  That they can provide  Attention on specific parts of the sentence  Now what is attention  And how it is provided  How the context of every word is taken out  We will study all this  When we will cover the deep learning part  Just understand that  After the arrival of Transformers  NLP which used to be in deep learning  It got a kind of  Boost  And very good models have started coming  All the state of the art models in today's date  Are based on all the Transformers  You might have heard the name  BERT  It is one of the Transformers  Which Google has trained  40 GB data  Which was on the internet  And you use it through transfer  You use it in many NLP applications  Lastly  Another architecture that you use  Is auto encoders  It is basically a set of  Two neural networks  Which are based on LSTM  Mostly  One is encoder and one is decoder  Which is used a lot  For machine translation etc  So this is  The whole landscape  Of NLP  The problem solving techniques  Which we are using  Are in these three umbrella categories  And you have to study these three things  Even if you don't understand  Some of these things  It is okay  I just wanted to give you an overview  And if you are missing some things  It is completely fine  Now if you talk to  An experienced NLP practitioner  He will tell you  That doing NLP is very difficult  Applying NLP is very difficult  And this is true  NLP is one of those  Technologies which  Can be applied in different  Application areas  Is a very challenging job  Now the question is  Why is it challenging?  Because NLP is  Applied on natural language  And natural language  Is a thing  Which has evolved over the years  And many times  You will see some weird things  In natural language  Now those weird things  We can understand  While talking to each other  But it becomes difficult to explain  That weird part to machines  Now you must be curious  What is the weird part?  I will tell you  I will give you 8 examples  Where you will understand  Why natural language processing  Is a challenging job  Now there can be more points  But I can see these 8 points clearly  So let's start with point 1  Point 1 is Ambiguity  Many times  Your sentences  Can have more than one meaning  Now since  Some human beings have evolved  We can understand  Which meaning is correct  But it becomes difficult to explain to machines  I will give you an example  In fact I am giving 2 examples  The first example is  I saw the boy on the beach  With my binoculars  Now there can be 2 meanings in this sentence  One meaning is  I saw a boy on the beach  Who had  My binoculars  Or it can mean  I saw a boy  Far away from my binoculars  On the beach  Now what is the meaning of this  From the context of the whole paragraph  I will understand  You will understand  But it is difficult to explain to machines  Let's see the next example  I have never tasted  A cake quite like that one  Before  Now after reading this sentence  And from the tone of the person  I will clearly understand  How he liked the cake  But after reading this sentence  Any NLP based software  Won't understand  Whether the person liked the cake or not  So ambiguity  Is a big problem  And guess what  The conversations we do on a day to day basis  There is a lot of ambiguity  The second reason  Because of which NLP is challenging  Is contextual words  Means  It is the same word  But in different contexts  The meaning is different  Again I will give you an example  The example is this  I ran to the store  Because we ran out of milk  Means it is very simple  That I ran to the shop  Because our milk ran out  But if you notice  The word ran is used twice  And both times  The meaning is different  Now as a human being for me  It is easy to understand  But for a machine  This is quite difficult  So this is the second reason  Third is  Colloquialism and slang  So basically  In our daily conversation  There is some common knowledge  Which you and I both know  So I will say something else  Which we both know  So we both can understand  But it is very difficult to understand machines  I will give you some examples  First example is piece of cake  So I will say this task is a piece of cake  Now I know that piece of cake  Means this work is easy  And you will also understand  Like you will listen to piece of cake  But machine will actually get confused  That this task is a piece of cake  So is it really a piece of cake  So that is difficult  Second example is pulling your leg  Now you can understand  Pulling your leg means  Making fun  But again if you go in a literal sense  Of this sentence  It means you are really pulling someone's leg  So there can be confusion  And like this  You will get phrases  They are called idioms  And in our language  It is spread  So it becomes difficult to understand machines  The next is synonyms  Synonyms means words  Which have the same meaning  It is the same meaning so keep one word  But what we do is  To express things better  We sometimes use synonyms  So the task of force  Is more difficult for the machine  The next one is irony  Sarcasm and tonal difference  So we want to say something  But we are saying something else  So that is weird  Sometimes because of the tone difference  The meaning of the sentence changes  I will give you one more example  Take this example  Suppose you have an interview  And you left home  And your crush saw you and said  All the best  So you would be happy and you would be saying  With this tone  That's just what I needed today  Second scenario  You left home and a crow patted you  And you would say  That's just what I needed today  So again  Because of the tonal difference  The meaning of the sentence is completely different  But again we can understand human beings  But  It is difficult for machines  The next one is spelling errors  It is very easy  Sometimes we are reading a paragraph  There are some spelling mistakes  And since we know  What the actual word is  We can read the paragraph  We can understand the context  We can communicate  But for a machine  As soon as the spelling mistake happened  It can't understand the meaning of the word  Because there is no meaning of the wrong word  So again this is a challenging task  Next is creativity  This is also a very challenging task  You will get a lot of text  We read poems  We write dialogues  We write scripts  It is a little challenging to understand the content of a machine  Because  If you talk about poems  Behind the scenes there is a subtext  The whole time something else is happening  And they are talking about something else  That is weird  Something else is coming out of the words  But something else is going on  So I hope you are understanding  Things like this  It becomes very difficult to understand the machine  And lastly  On top of everything  The language  As far as I know  There are 7000 languages in the world  To understand all of them  To decode everyone's grammar  And to understand everything  And to make an NLP application for it  Is extremely difficult  Even today  The major languages are being focused  On them  We have made some kind of a command  But if you say  In a local dialect  That you can make an NLP application  That is extremely challenging  Because  If it is a very rare kind of language  You won't get enough data to train your machine  So there are such challenges  In today's date  We will be at 5% of NLP  From its true potential  We have reached only 5%  And 95%  Because such challenges are in front of us  So  I wanted to discuss this because  If you want to become an NLP  Practitioner or engineer  You should know  What kind of challenges you will face  And maybe gradually  You will understand how to solve it  So that was the video guys  I hope you liked it  And you understood a basic level  Introduction about NLP  Now I told you  In the beginning of the video  That I will give you an assignment  Although whatever we read was theoretical  If there are any coding related assignments  It is not possible  But I will give you an interesting assignment  Your assignment is  That the whole video you watched  You have to write a blog  On medium.com  By the title  The NLP landscape  From 1960s to 2020s  Okay  And in that whatever you read in the video  And do some more research  From the side  Write a blog about NLP  And its history  And if possible  Then publish it on LinkedIn  And tag me too  I will see what you have written  So again if you are serious  Then you can do this assignment  Otherwise I will give you more  Coding related assignments  Which you call  Conventional assignments  I will give you such assignments  But for this video this is the assignment  So one last request  If you liked the video  Then please like it  It is taking a lot of effort to make  So please like it  And if you have not subscribed to the channel  Then please subscribe  So that's it from my side  We will meet next Thursday  With the second lecture  Bye\n",
            "Transcript saved to: transcript.txt\n",
            "Transcript segments saved to: transcript_segments.json\n"
          ]
        }
      ],
      "source": [
        "# Cell 4\n",
        "\n",
        "import moviepy.editor as mp\n",
        "from tqdm.notebook import tqdm\n",
        "import torch,json,os\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
        "    \"\"\"Extract audio from video using MoviePy.\"\"\"\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(audio_path)\n",
        "    video.close()\n",
        "    return audio_path\n",
        "\n",
        "def transcribe_audio(audio_path, model_name=\"medium\"):\n",
        "    \"\"\"Transcribe and translate audio using faster-whisper with a progress bar.\"\"\"\n",
        "    # Load the Whisper model\n",
        "    model = WhisperModel(\n",
        "        model_name,\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        compute_type=\"float16\"\n",
        "    )\n",
        "\n",
        "    # Perform transcription with translation task\n",
        "    segments, info = model.transcribe(audio_path, task='translate', beam_size=5)\n",
        "\n",
        "    # Prepare output containers\n",
        "    transcript = \"\"\n",
        "    transcript_segments = []\n",
        "\n",
        "    # Wrap the segments iterator with tqdm for progress bar\n",
        "    for segment in tqdm(segments, desc=\"Transcribing\"):\n",
        "        transcript += segment.text + \" \"\n",
        "        transcript_segments.append({\n",
        "            \"start\": segment.start,\n",
        "            \"end\": segment.end,\n",
        "            \"text\": segment.text\n",
        "        })\n",
        "\n",
        "    return transcript.strip(), transcript_segments\n",
        "\n",
        "\n",
        "def save_transcription(transcript, transcript_segments, txt_path=\"transcript.txt\", json_path=\"transcript_segments.json\"):\n",
        "    \"\"\"Save the transcript and segments to files.\"\"\"\n",
        "    try:\n",
        "        # Ensure output directory exists\n",
        "        directory = os.path.dirname(txt_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "        # Save full transcript to .txt\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"Transcription:\\n\\n\")\n",
        "            f.write(transcript)\n",
        "        print(f\"Transcript saved to: {txt_path}\")\n",
        "        directory = os.path.dirname(json_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        # Save transcript segments to .json\n",
        "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(transcript_segments, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Transcript segments saved to: {json_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving transcription: {e}\")\n",
        "        raise\n",
        "\n",
        "audio_path = extract_audio(video_path)\n",
        "print(\"Audio extracted to:\", audio_path)\n",
        "\n",
        "# Cell 5: Transcribe Audio\n",
        "transcript, transcript_segments = transcribe_audio(audio_path)\n",
        "print(\"Transcription completed.\", transcript)\n",
        "save_transcription(transcript, transcript_segments,txt_path=\"transcript.txt\",json_path=\"transcript_segments.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy7yWrLRvpq4",
        "outputId": "9cf75a5d-8806-468b-f98d-cbc3578891a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Insightful Multi-Chunk Summary ---\n",
            "\n",
            "In this first lecture, I will talk about introduction to NLP.\n",
            "– Introduction to Natural Language Processing – What is NLP and what is its need? – What are the biggest challenges in today's date in front of NLP that have stopped NLP?\n",
            "In the last two minutes, you will see a short introduction to the field of Natural Language Processing, NLP, or learning to understand natural language.\n",
            "We're going to talk about NLP.\n",
            "explains how natural language processing helps human beings\n",
            "What is the first factor which has put us on the path of growth?\n",
            "You don't know what to do with the machines\n",
            "And next I will talk about some real world applications\n",
            "This is an overview of the NLP project which is being undertaken by Microsoft and the companies using it.\n",
            "We are learning through NLP.\n",
            "NLP is a powerful and powerful tool which helps us in filtering spam, identifying inappropriate content, and removing the adult content in social media.\n",
            "NLP is a very powerful tool that can help in a lot of different areas from making applications to making search engines.\n",
            "You have to think about your use of NLP\n",
            "Identify types of information and how they are structured and used. Identify the source of information and how it's structured. Identify the source of information and how it is structured.\n",
            "The next topic is language detection and machine translation\n",
            "On the right side of this page you can see Google Translate\n",
            "You have a big text and you have a big topic to extract information from it, You want to use a lot of NLP techniques like: X-ray Scanners\n",
            "And the final application is a sorting engine which can sort all your text based on your previous typing habits So this is also a sorting engine which you can use for text generation if you want\n",
            "See the different tasks that a NLP engineer will be working on.\n",
            "During the course you will work on 10-12 things and you will learn how those things are made and what approaches we used in making those things.\n",
            "Heuristic methods were used in the 1950s and the 90s and deep learning was started in 2010\n",
            "The rule-based approach is very simple to follow but it's not always suitable for all situations. It's very simple to implement but it's not always suitable for all situations. It's very simple to implement and is very useful. It's very easy to implement and is very useful.\n",
            "Now, a wordnet is basically a dictionary, a kind of lexical dictionary.\n",
            "Learn about the NLP community in a dictionary.\n",
            "In heuristic approaches you can make a rule that makes a person sit.\n",
            "machine learning\n",
            "Using machine learning in textual data\n",
            "Do you have any questions about the video?\n",
            "Now you will see there are many different architectures in deep learning\n",
            "Understand what deep learning is\n",
            "Identify the umbrella categories and you have to study these three things Even if you don't understand Some of these things It is okay I just wanted to give you an overview And if you are missing some things It is completely fine I will give you 8 examples where you will understand Why natural language processing Is a challenging job\n",
            "We do not want to explain why a person might say something like that.\n",
            "Understand the ambiguity\n",
            "In the next part I will show you some examples of idioms, synonyms, irony and so on.\n",
            "Watch the video and learn about how we communicate with each other.\n",
            "Insight: You'll get a list of tasks, challenges and insights\n",
            "For the first time I want to introduce you to NLP and I am sure this is not the first time that you have seen this. Let's get started.\n",
            "Now after the first lecture we will meet on Thursday with the second lecture.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 5\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Load FLAN-T5 (base or large depending on your hardware)\n",
        "model_name = \"google/flan-t5-large\"  # You can use \"flan-t5-base\" or \"flan-t5-xl\" based on your GPU/CPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Put model on GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def chunk_text(text, max_tokens=1024):\n",
        "    import textwrap\n",
        "    return textwrap.wrap(text, max_tokens)\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    prompt = \"Summarize this with insight:\\n\" + chunk\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "    summary_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=150,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        do_sample=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "chunks = chunk_text(transcript, max_tokens=1024)\n",
        "summaries = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "# Join all chunk summaries\n",
        "final_summary = \"\\n\".join(summaries)\n",
        "\n",
        "print(\"\\n--- Insightful Multi-Chunk Summary ---\\n\")\n",
        "print(final_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdJ1ZrNV2rQh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 6\n",
        "import torch\n",
        "\n",
        "# Clear CUDA memory cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zaaebqPLhi_",
        "outputId": "4c54f0ff-61c6-46d9-f3b3-ed0af3ccbefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Only 13 sentences with timestamps found, requested 30\n",
            "Selected 13 key sentences for extractive summary\n",
            "✅ Summary saved to: my_summary.txt\n",
            "\n",
            "🔹 Extractive Summary (20 Key Sentences):\n",
            "\n",
            "1. We will start with the most important question that is what is NLP? (Start: 46.00s, End: 52.00s)\n",
            "2. We need to understand the importance of NLP  We will see that in the next slide  Where we will discuss the need for NLP  To understand this need, it is important to understand what natural language is  So again, I have taken out a definition of natural language from Wikipedia  I will quickly show you  So the definition is  In neuropsychology, linguistics and philosophy of language  A natural language or ordinary language  Is any language that has evolved naturally in humans  Through the use and repetition without conscious planning or premeditation  Natural language can take different forms  It can be speech or sign  They are distinguished from constructed and formal language  Such as those used to program computers or to study logic  So what is natural language? (Start: 272.00s, End: 274.00s)\n",
            "3. So after reading all this, I think you will have an opinion form about NLP  Which will help you a lot in the future videos  So I have two requests from you  First request is that please watch the video end to end if you are serious about this course  And second request is that I will give you an assignment at the end of this video  I will give you an assignment at the end of every video at least  But you will also get an assignment at the end of this video  You complete that assignment  So now let's start the video  So guys, let's start with the first topic  First of all, we will discuss what is NLP and what is its need  So I have picked this definition from Wikipedia  So I am assuming that it is correct  Let's read it out once because I found this definition to be correct  Natural language processing is a subfield of linguistics, computer science and artificial intelligence  Concerned with the interactions between computers and human language  In particular, how to program computers to process and analyze large amounts of natural language data  So if you see this diagram on the right side, you will see that NLP is a field that is made up of three fields  The first field is human language, which you call linguistics  Second is computer science, which we are all aware of  And third is artificial intelligence  These three are made up of NLP  And the most important goal of NLP is to teach machines natural language  The idea is that not only machines can understand natural language  But they can also communicate in it  When we say something, they understand it  And when they also say something, it is in the natural language  So that is the whole idea  This field is quite new  Work on this has started in the last 50 years  And now in the last 10 years, there has been a lot of growth  Especially since deep learning has come, this field has started to bloom more  Now the question is this, why is this field important? (Start: 136.00s, End: 143.00s)\n",
            "4. And why do we need NLP? (Start: 52.00s, End: 55.00s)\n",
            "5. It's a very simple thing  NLP is a difficult topic and I believe that if you are going to read any difficult topic  Before approaching it, you should take an overview  You can see the important information in the left and right center  And after that, cover the difficult topics  That is why I have decided in detail that I will give you a good introduction of NLP  What will we read in this video? (Start: 39.00s, End: 44.00s)\n",
            "6. Hello guys, my name is Nitesh and you are welcome to my YouTube channel  So as it was decided, from today we are going to start our natural language processing course  And today in this first lecture, I will talk about introduction to NLP  Why is the entire lecture on introduction? (Start: 10.00s, End: 16.00s)\n",
            "7. Because if you are making a chatbot  Or a question answering system  Then there you should  Understand word by word  What the sentence is saying  This part of speech tagging  Helps a lot  And that is why this is a very important  Text preprocessing step  The next task is  Language detection and machine translation  If you have ever used Google translate  Then you would know  That it is such a powerful application  Where you can say anything  In any language  And translate it in any other language  Internally it is an NLP task  Where you are first of all  Detecting the language  And then  Based on the output  Which language you want  You translate it in that language  So here deep learning is used  In the future when we read it in more detail  You will know but again  This is a very very important task  Next is conversational agents  Like I gave you the example of Swiggy  This is kind of a chatbot  But there are two types of chatbots  One is text based  One is speech based  Like Siri is speech based  And the Swiggy you are using  Is text based  So again it is  A very very important  NLP application  Next one is very interesting  It is called knowledge graph  And QA system  If you have a big database  Of things  Then you can logically connect  Its entities to each other  And make a knowledge graph  After making it  You can translate it  Into a question answering system  Google actually uses this  Google's knowledge graph is  The biggest in the world  And they had a big database  Of things  They connected important entities  To each other  And made a big knowledge graph  Because of which  If you do queries like this  Who is the Prime Minister of Japan  So this is again  A very very important and  A little advanced level of NLP  Next is  Text summarization  This is a very interesting task  I read about this  When I found out about  InShots news application  So they used this internally  I don't know exactly  But I think they used this  If they have a full fledged article  Then you can summarize  You can give a small form  InShots also does this  That it gives you a news summary  In 60 words  Of every news  So again it is a NLP application  Which you are going to see in the future  The next one is  Topic modeling  This is also a very interesting task  What happens here is  If you have a big text  Then you can extract  The abstract topics  You can extract that information  Like if you have a big text  About cricket  Then you can read it  And extract this information  That the text is  About cricket  Is it about IPL, is it about Sachin  So you use this  In many different places  And here  Internally you use a machine learning algorithm  Which we call  LTA  So again we will cover this  In detail  I am going to do an entire  Lecture on topic modeling  So you will understand better  After that  There is text generation  I guess you have used this a lot  That in today's date  The keyboards you have  When you type  It automatically  On the basis of your previous typing behavior  Predicts what your next word should be  And we all know  How useful it is  While chatting with someone  Next is  Spell checking and grammar correction  So if you have used a tool like Grammarly  Then  What it does is  If there is a typo in your sentence formation  Or if you have done grammatical errors  Then it will quickly highlight it  So that you can improve it  So this is also an application  The second  Last one is  Text parsing  As you can see on the screen  You have a sentence  And you are breaking it down  Grammatically  So that you can explain to the machine  What the meaning of that sentence is  What it means  So again in making chatbots  Text parsing is an important  Pre-processing step  We will discuss this in the future  And the last one is speech to text  Where you make conversational agents  Like Siri and all  And  What happens is  You basically say something  And you convert it into text  And then you try to understand the text  And then there is a reverse process  You generate the results  And then you convert it back into speech  So this is also an important aspect  In today's date  Whenever you want to talk to the machine  And you don't want to type  So you use this type of technology  So this is  10-12 important  NLP tasks  In the future when you become an NLP engineer  And work in a company  So most likely you will work  On one or two of these  It is not possible to work on all of them  But more or less you will work  On these 10-12 things  More than this you may not have to  Study in NLP  Now you must be thinking  How all these things are made  So next I am going to explain  That in today's date  All the things that we have made in NLP  How they were made  What approaches we used  In making those things  We will discuss that next  So before discussing the approaches  I will just give you a disclaimer  That it is possible that  Whatever I tell you in this section  You didn't understand it completely  Because you will read all these things  But to take an overview  It is necessary  So you have to just understand  The core idea  So we are discussing  Whatever we have achieved  In the field of NLP  How we achieved it  What techniques we used  To achieve  Those applications  To build those applications  So 3 different approaches  That we used  I will show you  The first one is called heuristic methods  Second is  Machine learning based models  And the third one is  Deep learning based models  NLP started in 1950s  And around 90s  Almost 40 years  Heuristic methods were used  I will tell you what heuristic methods are  From 90s  The era of machine learning started  And from around 2010  The era of deep learning started  Which is still going on  So these 3 methods are still used  And they have their own impact  We will discuss them one by one  First of all  Let's discuss heuristic approaches  So let's go behind the word  What is heuristic  So you can see  If you see the meaning of heuristic  It is written here  A heuristic technique is any approach  To problem solving  Or self discovery  That employs a practical method  That is not guaranteed  To be optimal, perfect  Or rational, but is nevertheless  Sufficient for reaching an immediate  Short term goal or approximation  So in short  You can say  Heuristic approaches  Means to solve a problem  Means  You had to solve a problem  Mostly  NLP practitioners  Created rule-based approaches  I will give you some examples  Let's say you have to create  A sentiment analysis app  Where you will find  A sentiment of a text  Is it positive or negative  A rule-based approach  Is very simple  Count the number of positive words  In that text  And the number of negative words  So you can put  Such approaches under  Heuristic approach  Now many different  Types of heuristic approaches  Came in the last 50-60 years  I will give you three examples  Of the most famous and used  Approaches  Apart from this there are many more  Which we will discuss further  The first is regular expressions  If you have coded in python  Then you might know that  For that matter in all programming languages  There is a feature of regular expression  So what is regular expression  You can  Form a text  And dig a pattern text  Into another text  I will give you an example  When we will scrape text from any website  I will get HTML tags  I don't want those HTML tags  Now HTML tags are of different types  What I have to do  Is remove all HTML tags  I can do this very easily  With regular expressions  Or you can take another example  That  In a whole paragraph  I have to find salutations  I have to find Mr., Mrs.,  Master, doctor, Ph.D  So to find this kind of  Pattern  I can use regular expressions  So the initial approaches  Of solving NLP problems  In that regular expression  Was a very important tool  Which NLP practitioners  Used a lot  In this course  We will discuss in at least one section  How regular expressions are used  In NLP  Apart from this  Another very famous approach  Was wordnet  What is wordnet  Wordnet is basically a lexical dictionary  So in a normal dictionary  What do you get  A word, its meaning  Its synonyms, its antonyms  A lexical dictionary  Like wordnet  What you do in this  The relationships of a word  With other words  You store them in a very organized way  I will give you one example  Like run  And jog  The relationship between these two  Is similar  Then shoes and run  The relationship is that while running  You use shoes  So all these mappings  Were already made  And stored in this dictionary  So that if you want to make  Any kind of NLP application  Like translation  Or parts of speech tagging  Or any complex NLP application  There this wordnet  Will help you a lot  So there is a wordnet  In the NLP library  During this course  But at this point  The third one is  Open mind common sense  This is a kind of  Community  Where  All the facts  In the language  All the facts  Were stored  And it was an open source  That anyone in the world  Can contribute  The common facts  In the English language  That you are storing  So that it becomes a big database  Of common facts  So that when you make NLP systems  You can look at that database  And retrieve your information  So this is how it used to work  I have given you 2-3 examples  If you read some more  You will understand better  Now the question is  What is the advantage of heuristic approaches  The biggest advantage is  These are quick approaches  You get the answers  As soon as possible  And it is very accurate  There are less chances of errors  Because you have made rules  By making a person sit  So it is very less to fail  Now one more question  In today's scenario  Are heuristic approaches used  The answer is yes  In the future when we will see machine learning  In the NLP domain  There you will realize  That we will take help  Of heuristic approaches many times  So even today it is needed  And it is used  Now let's move on to the second approach  The second approach is machine learning  When the revolution of machine learning  Came in the 90s  It impacted NLP  The way we work with other types of data  In machine learning  Similarly you work with textual data  So first of all let's discuss  What is the big advantage  Of machine learning approaches  What was the advantage of heuristic approaches  The advantage was very simple  And very impactful  The advantage was  You make rules in heuristic approaches  Now there are some open-ended problems  Where making rules is not that possible  For a human being  Because there are too many rules  The problem is very open-ended  So in that situation  Machine learning approaches were useful  Because the rules in machine learning  Are made by your algorithm  Internally  The relationship between input and output  Is decided by looking at the data  And not by making a general rule  So that's why  Machine learning  The open-ended problems  In NLP  Were very useful in solving them  And slowly it became the go-to approach  To solve NLP problems  Heuristic approaches are used  But machine learning approaches  Are used in more powerful and wide variety  Of problems  Now you can ask  What is the entire workflow  How do you solve an NLP problem  It's quite similar  What you have to do is  Convert textual data into a number  Which is called text vectorization  Then you give that number  In a machine learning algorithm  And then you evaluate  The output  And that's it  The typical machine learning  Is done on normal data  In the same way  You do it on textual data  In fact you may have used  This type of flow  Maybe you have made a spam filter  Or you have done some other projects  Where machine learning is working on textual data  Now you can ask  Which algorithms should we read  So the most used algorithms  Let me tell you their names  First is Naive based  Probability based algorithm  Which gives very good results on textual data  Second is Logistic regression  Again a classification algorithm  Which gives you very good results  Third is SVM  Universally powerful algorithm  Third is LDA  LDA is used for a particular task  Called topic modeling  In which it is used  And the last one is hidden Markov models  Like POS tagging  Which I told you  Parts of speech tagging  Hidden Markov models can be used  So these 4-5 algorithms are the most used  So this was the machine learning  Approach  Now let's discuss deep learning  Approaches  So again the first question is  What is the advantage  Of deep learning  Over machine learning  That deep learning is used  So the first question is  What is the big advantage  There are two big advantages  Of deep learning based approaches  Over machine learning approaches  Let me tell you one by one  The first advantage is  In machine learning approaches  We convert textual data into numbers  And when we convert it into numbers  Most of the times  The sequential information  Of the text gets loosed  Machine learning algorithms  Are designed in such a way  That they don't care  About the sequential information  Which is present  Inside the text  But deep learning based models  Use this sequential information  Which means  Sentence formation  Is left to right in English  This is my house  So this sequence matters  You can't write like this  So retaining this sequential information  Deep learning has a big advantage  Because of which  The results are very good  Second  The biggest advantage of deep learning  Is that  The feature generation  Automatically models your deep learning  Whereas in machine learning  You have to make it yourself  According to your understanding  So this is also a big advantage  Now if you ask  Which architectures are used the most  In deep learning  I would say  Not the most used  But the first used was RNN  Recurrent Neural Network  Which gives very good results on sequential data  Be it textual data or time series data  It gives you very good results  The only problem is  If you provide  A very long sentence  Then  The context inside it  Can't be retained  Then LSTM came  Long short term memory  Its speciality is  That it can retain the context of big sentences  Its memory factor  Was better than RNN  So in today's date  Most NLP applications  In deep learning are based on LSTM  The third architecture is  CRU  Gated Recurrent Unit  This is used a lot for text generation  Then there is CNN  CNN is actually  Mainly used for image classification  Etc  But in some certain NLP applications  You will see that CNN is also used  Like text classification  After that  Transformers came in 2015  And after that  Things got revolutionized  The speciality of Transformers is  That they can provide  Attention on specific parts of the sentence  Now what is attention  And how it is provided  How the context of every word is taken out  We will study all this  When we will cover the deep learning part  Just understand that  After the arrival of Transformers  NLP which used to be in deep learning  It got a kind of  Boost  And very good models have started coming  All the state of the art models in today's date  Are based on all the Transformers  You might have heard the name  BERT  It is one of the Transformers  Which Google has trained  40 GB data  Which was on the internet  And you use it through transfer  You use it in many NLP applications  Lastly  Another architecture that you use  Is auto encoders  It is basically a set of  Two neural networks  Which are based on LSTM  Mostly  One is encoder and one is decoder  Which is used a lot  For machine translation etc  So this is  The whole landscape  Of NLP  The problem solving techniques  Which we are using  Are in these three umbrella categories  And you have to study these three things  Even if you don't understand  Some of these things  It is okay  I just wanted to give you an overview  And if you are missing some things  It is completely fine  Now if you talk to  An experienced NLP practitioner  He will tell you  That doing NLP is very difficult  Applying NLP is very difficult  And this is true  NLP is one of those  Technologies which  Can be applied in different  Application areas  Is a very challenging job  Now the question is  Why is it challenging? (Start: 228.00s, End: 234.00s)\n",
            "8. Then we will see what kind of applications NLP is being used in today's date  And then we will see what are some common NLP tasks  After that, I will cover one more topic where I will discuss  What kind of approaches have been used till date to make these NLP applications  And lastly, we will see one more very important topic  What are the biggest challenges in today's date in front of NLP that have stopped NLP? (Start: 75.00s, End: 81.00s)\n",
            "9. According to this definition  Humans have been evolving for many years  So if we come up with a way to communicate with each other  And improve it over the years  Then eventually it becomes a language  You can speak through speech or through signs  As you must have seen on some news channels  You tell the news through sign language  And this natural language is different from constructed languages  Such as our programming languages  It is very different from these  So why did I tell you this definition of natural language? (Start: 306.00s, End: 310.00s)\n",
            "10. Because NLP is  Applied on natural language  And natural language  Is a thing  Which has evolved over the years  And many times  You will see some weird things  In natural language  Now those weird things  We can understand  While talking to each other  But it becomes difficult to explain  That weird part to machines  Now you must be curious  What is the weird part? (Start: 186.00s, End: 191.00s)\n",
            "11. Because I want to explain to you why NLP is needed  Now I will use a small story to explain to you  Why NLP is important  So if you read a little bit of human history  Or read a little bit of human evolution  Then you would notice  That in the beginning, millions of years ago  Our ancestors used to live in the jungle like other animals  And used to spend a very normal animal life  But fast forward a million years  We have evolved a lot  Today we are going into space  Whereas if you look at other animals  They are still doing the same work  So the question is  What did we do differently  That we went so far  So if you ask me  One of the most important factors  Which I feel is  The first factor is communication and language  Whatever we achieved  There was a big factor behind it  That we were able to talk to each other  We were able to explain our ideas to each other  Books came  And a lot of teachers came  And they passed on a lot of things in the next generation  We read things from the previous generation  And moved forward  So that is how our evolution has happened  So language and communication  This is the thing  Which has put us on the path of growth  Now if you ask me  What is the second factor which has moved us a lot  So I would say the second factor is machines  If you look at 300-400 years ago  Industrial revolution came  And after that our evolution  It has completely escalated  It has started to grow very fast  We have brought machines in every domain  And today if you look  The machines and the internet  How much we have moved forward  Now I feel  A third revolution  A third factor is still to come  And that is  When we can talk to machines  Just like we do with our fellow human beings  Even today if you talk about machines  It is not that easy to talk to them  When machines were there in the beginning  To run them  You used to use mechanical things  Like levers and all  Then when electronic machines came  You started using switches  Now when the era of computer science came  You started to program them  But not everyone is able to program  There are very specialized computer science engineers  Who program these machines  Can a normal person still run the machine so well? (Start: 220.00s, End: 223.00s)\n",
            "12. No  Even today if you want to run your smartphone  You have to point with your hands  Now imagine a world  Where you can talk to any machine  Absolutely easily  Just like you  Are talking to a human being  Then imagine how fast  Our progress will be  Imagine you are standing in an ATM machine  And a good person comes there to withdraw money  And he doesn't understand  What is the interface  He can simply ask him  And the machine is telling him  To press the button  And he is explaining everything  Like a human being is talking  So that is the next frontier  The next frontier of evolution  Is that we should talk  With our machines  Just like we talk with  Any other human being  And then you will see  That we will be able to evolve  Now it's not like there is no growth  Or we are not able to talk with machines  Take the example of Google Now  Take the example of Siri  Take the example of Cortana  These are some examples  Where we are trying to talk with machines  Where this is possible  But that is the dream  That we have to evolve more  So NLP is one of those things  Which when it will come  In our life  It will revolutionize  The entire humanity  So that is why NLP is  Very very important  And today every big company  Is investing money on NLP  Is making efforts on NLP  That we should become the first company  To take NLP forward  Now next I will tell you  Some applications  Which we are already using  For NLP  So guys now I will discuss two things with you  First some real world applications  Which already  Companies are putting in their product  And giving it to customers  And second I will tell you  About some common NLP tasks  If you want to become an NLP engineer  Then these are some 10-12 tasks  Which you can perform  And make many types of NLP applications  So these are like some common tasks  Which every NLP engineer should get  So let's start with some  Real world applications  Now applications are very simple  You might have seen  Chatbots or CD  Or Cortana  These are all examples of NLP applications  But I will tell you some different types of examples  Which will help you develop  Your perspective  For me personally  An NLP application  Kind of inspires  And seems very intriguing  Those are contextual  Advertisements  In the earlier world  Like if you go 20-25 years ago  Then I remember  When we used to watch matches on TV  Then the whole of India  Used to be shown the same advertisements  The company's assumption was  To show it to everyone  But today  Since we have NLP  We can process  How people behave  How their personality is  So we can actually  Run targeted advertisements  So if you noticed  Depending on your Facebook profile  Or Instagram profile  You can see different ads  From your friends  The company analyzes  Your profile, posts, comments  And then decides on the basis  That this person is very interested in sports  Or this person is very interested in cosmetics  And you can see targeted ads  Of those same things  In fact, if I tell you the truth  I feel like we are being tracked  Like if I chat a lot  On WhatsApp  On a topic  And if I use another application  Then I can see ads  About the topic I was chatting with my friend  Sometimes my phone is  Next to me  And I am talking about something  And as soon as I opened the phone  I can see ads about that  So the science behind all these things  That is contextual advertisements  And that is powered  Through NLP  The next one is  Email clients  If you have used Gmail  You must have noticed that there is spam filtering  If your email  Is spam  It automatically goes to the spam folder  And normal emails  Come to your normal folder  In fact, there are some new features  Like smart reply  So if you get an email  Then you get a suggestion  Of smart replies  And that suggestion is based on  What is the content of your email  So this is the second application  The third application is social media  One of the challenging tasks  Is removing adult content  So if you think about it  If you are making a social media platform  Then there is a big challenge  Because your platform is scaling  In crores of users  So in crores of users there can be  People who put such content on your platform  Which is not right for everyone  Like adult content  So how to filter that  Or if someone is saying very negative  Or spreading hate speech  Then how to block such things  All this is done through NLP  One more thing on social media  Is opinion mining  So if you take the example of twitter  So if a lot of people  Are talking about a topic  Then what twitter does  Is it picks up their opinion  And creates a sentiment  And uses it according to their knowledge  I gave an example of this  On my channel  Depending on the tweet  About the election  Twitter already knows  Which leader will win the election  Because  From the content of the tweet  Which leader is being supported  So these are all applications  The next one is search engines  Google  In the last 10-15 years  Google has evolved a lot  And there are a lot of new features  And that has become possible  Because of NLP  I can tell you a small feature  If you ask a question of general knowledge  Like what is the capital of Srilanka  Let's say  You don't need to go inside the website  And find out  What is the capital of Srilanka  Google will fetch that information for you  And show it in one line  So such small changes  Which happen in search engine  Are also NLP powered  In fact the functionality of search engine  Also uses a lot of NLP  Internally  One more example is chatbots  As I told you  Let's say  You are ordering food on Swiggy  And you don't like anything  As soon as you go on chat  There is a chatbot  And it talks like  A customer executive  So it  Made Swiggy very easy  Because on the scale  On which Swiggy is working  Customers have to handle together  It is not possible to have so many customer executives  So the chatbot  Tries at the initial level  To solve that problem  And if it doesn't work  Then it reroutes us to the customer executive  So again chatbots are very important  And that's it  There are many more examples  And I would actually  Ask you to think about this  You sit and think  That you use so many products  And what NLP is being used  It's a good thinking exercise  So now  I will discuss with you  Some common NLP tasks  Since we have to become an NLP engineer  We have to learn NLP  So there are some common tasks  Which you use to make such applications  So I have around 10 tasks  I will discuss with you one by one  The first common task  Is text or  Document classification  So suppose you have a big  Text and you  Have to put it in a particular category  One example could be  That you have a news  Full text  And you have to assign it a category  Like sports  Or entertainment or politics  You can do it very easily  Using text or document classification  The second task  Is sentiment analysis  This is also used a lot today  In e-commerce  Or social media  You read reviews  And you extract  Emotions from people's reviews  About what they are feeling  About a product or a movie  So companies use this a lot  Let's say I have a product  Which has 1 crore reviews  Now if I am asked to read  One review  I will have to waste  A lot of human hours  It will take a lot of time  To find out people's sentiment  It is very easy to make  An NLP application  In which you feed  All the 1 crore reviews  And it will tell you a percentage  That 80% of people are feeling positive  About your product  So this can save you a lot of money  If you are a big company owner  Next is  Information retrieval  As you can see on your screen  If you have a text  And you have to extract entities  Like date  Or person's name  Or product's name  Or event's name  If you want to extract  This comes under information retrieval  I gave you an example of a search engine  Search engines internally  Use information retrieval  In the future  We will cover a topic  Which will be named entity recognition  Where we will do exactly this  The next one is  Parts of speech tagging  This is a very important  Text preprocessing step  Where you  Assign every word  To a part of speech  Whether it is noun, verb or adjective  Why does it work? (Start: 425.00s, End: 427.00s)\n",
            "13. I will tell you  I will give you 8 examples  Where you will understand  Why natural language processing  Is a challenging job  Now there can be more points  But I can see these 8 points clearly  So let's start with point 1  Point 1 is Ambiguity  Many times  Your sentences  Can have more than one meaning  Now since  Some human beings have evolved  We can understand  Which meaning is correct  But it becomes difficult to explain to machines  I will give you an example  In fact I am giving 2 examples  The first example is  I saw the boy on the beach  With my binoculars  Now there can be 2 meanings in this sentence  One meaning is  I saw a boy on the beach  Who had  My binoculars  Or it can mean  I saw a boy  Far away from my binoculars  On the beach  Now what is the meaning of this  From the context of the whole paragraph  I will understand  You will understand  But it is difficult to explain to machines  Let's see the next example  I have never tasted  A cake quite like that one  Before  Now after reading this sentence  And from the tone of the person  I will clearly understand  How he liked the cake  But after reading this sentence  Any NLP based software  Won't understand  Whether the person liked the cake or not  So ambiguity  Is a big problem  And guess what  The conversations we do on a day to day basis  There is a lot of ambiguity  The second reason  Because of which NLP is challenging  Is contextual words  Means  It is the same word  But in different contexts  The meaning is different  Again I will give you an example  The example is this  I ran to the store  Because we ran out of milk  Means it is very simple  That I ran to the shop  Because our milk ran out  But if you notice  The word ran is used twice  And both times  The meaning is different  Now as a human being for me  It is easy to understand  But for a machine  This is quite difficult  So this is the second reason  Third is  Colloquialism and slang  So basically  In our daily conversation  There is some common knowledge  Which you and I both know  So I will say something else  Which we both know  So we both can understand  But it is very difficult to understand machines  I will give you some examples  First example is piece of cake  So I will say this task is a piece of cake  Now I know that piece of cake  Means this work is easy  And you will also understand  Like you will listen to piece of cake  But machine will actually get confused  That this task is a piece of cake  So is it really a piece of cake  So that is difficult  Second example is pulling your leg  Now you can understand  Pulling your leg means  Making fun  But again if you go in a literal sense  Of this sentence  It means you are really pulling someone's leg  So there can be confusion  And like this  You will get phrases  They are called idioms  And in our language  It is spread  So it becomes difficult to understand machines  The next is synonyms  Synonyms means words  Which have the same meaning  It is the same meaning so keep one word  But what we do is  To express things better  We sometimes use synonyms  So the task of force  Is more difficult for the machine  The next one is irony  Sarcasm and tonal difference  So we want to say something  But we are saying something else  So that is weird  Sometimes because of the tone difference  The meaning of the sentence changes  I will give you one more example  Take this example  Suppose you have an interview  And you left home  And your crush saw you and said  All the best  So you would be happy and you would be saying  With this tone  That's just what I needed today  Second scenario  You left home and a crow patted you  And you would say  That's just what I needed today  So again  Because of the tonal difference  The meaning of the sentence is completely different  But again we can understand human beings  But  It is difficult for machines  The next one is spelling errors  It is very easy  Sometimes we are reading a paragraph  There are some spelling mistakes  And since we know  What the actual word is  We can read the paragraph  We can understand the context  We can communicate  But for a machine  As soon as the spelling mistake happened  It can't understand the meaning of the word  Because there is no meaning of the wrong word  So again this is a challenging task  Next is creativity  This is also a very challenging task  You will get a lot of text  We read poems  We write dialogues  We write scripts  It is a little challenging to understand the content of a machine  Because  If you talk about poems  Behind the scenes there is a subtext  The whole time something else is happening  And they are talking about something else  That is weird  Something else is coming out of the words  But something else is going on  So I hope you are understanding  Things like this  It becomes very difficult to understand the machine  And lastly  On top of everything  The language  As far as I know  There are 7000 languages in the world  To understand all of them  To decode everyone's grammar  And to understand everything  And to make an NLP application for it  Is extremely difficult  Even today  The major languages are being focused  On them  We have made some kind of a command  But if you say  In a local dialect  That you can make an NLP application  That is extremely challenging  Because  If it is a very rare kind of language  You won't get enough data to train your machine  So there are such challenges  In today's date  We will be at 5% of NLP  From its true potential  We have reached only 5%  And 95%  Because such challenges are in front of us  So  I wanted to discuss this because  If you want to become an NLP  Practitioner or engineer  You should know  What kind of challenges you will face  And maybe gradually  You will understand how to solve it  So that was the video guys  I hope you liked it  And you understood a basic level  Introduction about NLP  Now I told you  In the beginning of the video  That I will give you an assignment  Although whatever we read was theoretical  If there are any coding related assignments  It is not possible  But I will give you an interesting assignment  Your assignment is  That the whole video you watched  You have to write a blog  On medium.com  By the title  The NLP landscape  From 1960s to 2020s  Okay  And in that whatever you read in the video  And do some more research  From the side  Write a blog about NLP  And its history  And if possible  Then publish it on LinkedIn  And tag me too  I will see what you have written  So again if you are serious  Then you can do this assignment  Otherwise I will give you more  Coding related assignments  Which you call  Conventional assignments  I will give you such assignments  But for this video this is the assignment  So one last request  If you liked the video  Then please like it  It is taking a lot of effort to make  So please like it  And if you have not subscribed to the channel  Then please subscribe  So that's it from my side  We will meet next Thursday  With the second lecture  Bye (Start: 186.00s, End: 191.00s)\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Define Functions\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "from faster_whisper import WhisperModel\n",
        "from scenedetect import VideoManager, SceneManager, ContentDetector\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Download NLTK tokenizer once\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "def save_transcription(transcript, transcript_segments, txt_path=\"transcript.txt\", json_path=\"transcript_segments.json\"):\n",
        "    \"\"\"Save the transcript and segments to files.\"\"\"\n",
        "    try:\n",
        "        # Ensure output directory exists\n",
        "        directory = os.path.dirname(txt_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "        # Save full transcript to .txt\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"Transcription:\\n\\n\")\n",
        "            f.write(transcript)\n",
        "        print(f\"Transcript saved to: {txt_path}\")\n",
        "\n",
        "        directory = os.path.dirname(json_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        # Save transcript segments to .json\n",
        "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(transcript_segments, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Transcript segments saved to: {json_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving transcription: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_extractive_summary(transcript, transcript_segments, num_points=10):\n",
        "    \"\"\"Generate an extractive summary by selecting key sentences from the transcript.\"\"\"\n",
        "    try:\n",
        "        # Tokenize transcript into sentences\n",
        "        sentences = nltk.sent_tokenize(transcript)\n",
        "        if not sentences:\n",
        "            raise ValueError(\"No sentences found in transcript\")\n",
        "\n",
        "        # Load sentence transformer for similarity-based matching\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
        "\n",
        "        # Map sentences to their corresponding segments for timestamps\n",
        "        sentence_segments = []\n",
        "        segment_texts = [seg[\"text\"] for seg in transcript_segments]\n",
        "        segment_embeddings = embedder.encode(segment_texts, convert_to_tensor=True)\n",
        "\n",
        "        for sent in sentences:\n",
        "            sent = sent.strip()\n",
        "            # Encode sentence\n",
        "            sent_embedding = embedder.encode(sent, convert_to_tensor=True)\n",
        "\n",
        "            # Compute cosine similarities to transcript segments\n",
        "            similarities = util.cos_sim(sent_embedding, segment_embeddings)[0].cpu().numpy()\n",
        "\n",
        "            # Select the best segment (highest similarity)\n",
        "            if similarities.max() > 0.5:  # Require minimum similarity\n",
        "                best_idx = similarities.argmax()\n",
        "                start = transcript_segments[best_idx][\"start\"]\n",
        "                end = transcript_segments[best_idx][\"end\"]\n",
        "                # Cap segment duration at 60s\n",
        "                if end - start <= 60.0:\n",
        "                    sentence_segments.append({\n",
        "                        \"text\": sent,\n",
        "                        \"start\": start,\n",
        "                        \"end\": end\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"Skipped sentence due to long duration: {sent} ({end - start:.2f}s)\")\n",
        "            else:\n",
        "                # Fallback: Match first 3 words\n",
        "                first_words = \" \".join(sent.split()[:3]).lower()\n",
        "                matched_segments = [\n",
        "                    seg for seg in transcript_segments\n",
        "                    if first_words in seg[\"text\"].lower() and seg[\"end\"] - seg[\"start\"] <= 60.0\n",
        "                ]\n",
        "                if matched_segments:\n",
        "                    # Take the first matching segment\n",
        "                    seg = matched_segments[0]\n",
        "                    sentence_segments.append({\n",
        "                        \"text\": sent,\n",
        "                        \"start\": seg[\"start\"],\n",
        "                        \"end\": seg[\"end\"]\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"Skipped sentence due to no matching segment: {sent}\")\n",
        "\n",
        "        if len(sentence_segments) < num_points:\n",
        "            print(f\"Warning: Only {len(sentence_segments)} sentences with timestamps found, requested {num_points}\")\n",
        "\n",
        "        # Encode sentences for relevance scoring\n",
        "        sentence_texts = [s[\"text\"] for s in sentence_segments]\n",
        "        embeddings = embedder.encode(sentence_texts, convert_to_tensor=True)\n",
        "\n",
        "        # Compute centrality scores (average cosine similarity to all sentences)\n",
        "        sim_matrix = util.cos_sim(embeddings, embeddings)\n",
        "        centrality_scores = sim_matrix.mean(dim=1).cpu().numpy()\n",
        "\n",
        "        # Select diverse sentences\n",
        "        selected_indices = []\n",
        "        used_indices = set()\n",
        "        sim_threshold = 0.7  # Avoid redundant sentences\n",
        "\n",
        "        # Start with the most central sentence\n",
        "        if len(centrality_scores) > 0:\n",
        "            first_idx = np.argmax(centrality_scores)\n",
        "            selected_indices.append(first_idx)\n",
        "            used_indices.add(first_idx)\n",
        "\n",
        "        # Iteratively select diverse sentences\n",
        "        while len(selected_indices) < min(num_points, len(sentence_segments)):\n",
        "            last_idx = selected_indices[-1]\n",
        "            sims = sim_matrix[last_idx].cpu().numpy()\n",
        "            candidate_indices = [\n",
        "                i for i in range(len(sentence_texts))\n",
        "                if i not in used_indices and sims[i] < sim_threshold\n",
        "            ]\n",
        "            if not candidate_indices:\n",
        "                break\n",
        "            # Prefer sentences with higher centrality\n",
        "            next_idx = max(candidate_indices, key=lambda i: centrality_scores[i])\n",
        "            selected_indices.append(next_idx)\n",
        "            used_indices.add(next_idx)\n",
        "\n",
        "        # Collect selected sentences with timestamps\n",
        "        key_points = [\n",
        "            {\n",
        "                \"text\": sentence_segments[i][\"text\"],\n",
        "                \"start\": sentence_segments[i][\"start\"],\n",
        "                \"end\": sentence_segments[i][\"end\"]\n",
        "            }\n",
        "            for i in selected_indices\n",
        "        ]\n",
        "\n",
        "        print(f\"Selected {len(key_points)} key sentences for extractive summary\")\n",
        "        return key_points\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating extractive summary: {e}\")\n",
        "        print(\"Suggestions:\")\n",
        "        print(\"- Ensure transcript contains valid sentences: !cat /content/drive/MyDrive/video_summarizer/transcript.txt\")\n",
        "        print(\"- Check sentence-transformers: !pip show sentence-transformers\")\n",
        "        print(\"- Run on CPU: set device='cpu'\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def save_summary_to_txt(key_points, file_path=\"my_summary.txt\"):\n",
        "    \"\"\"Save the list of summary key points with timestamps to a .txt file.\"\"\"\n",
        "    try:\n",
        "        directory = os.path.dirname(file_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"Extractive Summary Key Points:\\n\\n\")\n",
        "            for i, point in enumerate(key_points, 1):\n",
        "                f.write(f\"{i}. {point['text']} (Start: {point['start']:.2f}s, End: {point['end']:.2f}s)\\n\")\n",
        "        print(f\"✅ Summary saved to: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary: {e}\")\n",
        "        raise\n",
        "\n",
        "key_points = generate_extractive_summary(transcript, transcript_segments, num_points=30)\n",
        "save_summary_to_txt(key_points, \"my_summary.txt\")\n",
        "print(\"\\n🔹 Extractive Summary (20 Key Sentences):\\n\")\n",
        "for i, point in enumerate(key_points, 1):\n",
        "    print(f\"{i}. {point['text']} (Start: {point['start']:.2f}s, End: {point['end']:.2f}s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgpQybgTMo1G",
        "outputId": "47f672d4-f642-4999-94d2-424c79ea0b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
            "INFO:pyscenedetect:Loaded 1 video, framerate: 30.000 FPS, resolution: 1920 x 1080\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 3 scenes\n",
            "Selected segments: [(46.0, 52.0), (272.0, 274.0), (136.0, 143.0), (52.0, 55.0), (39.0, 44.0), (10.0, 16.0), (228.0, 234.0), (75.0, 81.0), (306.0, 310.0), (186.0, 191.0), (220.0, 223.0), (425.0, 427.0), (186.0, 191.0)]\n",
            "Selected 13 segments for summary, total duration: 60.00 seconds\n",
            "Selected Segments [(46.0, 52.0), (272.0, 274.0), (136.0, 143.0), (52.0, 55.0), (39.0, 44.0), (10.0, 16.0), (228.0, 234.0), (75.0, 81.0), (306.0, 310.0), (186.0, 191.0), (220.0, 223.0), (425.0, 427.0), (186.0, 191.0)]\n",
            "Total Duration: 60.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 8: Define Functions\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import torch\n",
        "import json\n",
        "from faster_whisper import WhisperModel\n",
        "from scenedetect import VideoManager, SceneManager, ContentDetector\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def detect_scenes(video_path, threshold=30.0):\n",
        "    \"\"\"Detect scene changes using PySceneDetect.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    video_manager = VideoManager([video_path])\n",
        "    scene_manager = SceneManager()\n",
        "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
        "    video_manager.set_downscale_factor(4)\n",
        "    video_manager.start()\n",
        "    scene_manager.detect_scenes(frame_source=video_manager)\n",
        "    scenes = scene_manager.get_scene_list()\n",
        "    video_manager.release()\n",
        "\n",
        "    scene_times = [(scene[0].get_seconds(), scene[1].get_seconds()) for scene in scenes]\n",
        "    return scene_times\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def rank_segments(scene_times, key_points):\n",
        "    \"\"\"Select exact video segments for summary sentences.\"\"\"\n",
        "    try:\n",
        "        selected_segments = [(point[\"start\"], point[\"end\"]) for point in key_points if point[\"end\"] - point[\"start\"] <= 60.0]\n",
        "        if len(selected_segments) < len(key_points):\n",
        "            print(f\"Filtered {len(key_points) - len(selected_segments)} segments with duration > 60s\")\n",
        "        print(f\"Selected segments: {selected_segments}\")\n",
        "        final_segments = selected_segments\n",
        "        total_duration = sum(end - start for start, end in final_segments)\n",
        "        print(f\"Selected {len(final_segments)} segments for summary, total duration: {total_duration:.2f} seconds\")\n",
        "        return final_segments, total_duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error selecting segments: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cell 8: Detect Scenes\n",
        "scene_times = detect_scenes(video_path)\n",
        "print(\"Detected\", len(scene_times), \"scenes\")\n",
        "\n",
        "# Cell 12: Create Summary Video\n",
        "selected_segments, total_duration = rank_segments(scene_times, key_points)\n",
        "print(f\"Selected Segments {selected_segments}\")\n",
        "print(f\"Total Duration: {total_duration}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "dd8d4811cf124cb3bd1c3c4f172f684a",
            "62ca7880689546a59f01f3da23e5182b",
            "973c4fa38631442e82a4ee7f1a159402",
            "72c296ef7690413880457982104f8955",
            "8285fb93924847b7a1652a3d16ea8a86",
            "f03ea51f69ef455ebf67e9a7b12421d9",
            "c0a09f817b314681a48ef00919dd7f25",
            "781788af0cbc4e759ce2e8bca84227ff",
            "43bb673204bc4cbe8174366b9055faae",
            "657883b7b33d4650bd471238b7680e6a",
            "e63426d3a969447ab35c424008e3f847"
          ]
        },
        "id": "8v9ZsP4iNudH",
        "outputId": "598d4aaa-3d62-4372-884c-2a955f15cba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disk space before processing:\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   54G   60G  48% /\n",
            "\n",
            "Extracting and re-encoding video clips...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing clips:   0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd8d4811cf124cb3bd1c3c4f172f684a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenating clips...\n",
            "Concat list contents:\n",
            "file '/tmp/temp_clips/clip_0.mp4'\n",
            "file '/tmp/temp_clips/clip_1.mp4'\n",
            "file '/tmp/temp_clips/clip_2.mp4'\n",
            "file '/tmp/temp_clips/clip_3.mp4'\n",
            "file '/tmp/temp_clips/clip_4.mp4'\n",
            "file '/tmp/temp_clips/clip_5.mp4'\n",
            "file '/tmp/temp_clips/clip_6.mp4'\n",
            "file '/tmp/temp_clips/clip_7.mp4'\n",
            "file '/tmp/temp_clips/clip_8.mp4'\n",
            "file '/tmp/temp_clips/clip_9.mp4'\n",
            "file '/tmp/temp_clips/clip_10.mp4'\n",
            "file '/tmp/temp_clips/clip_11.mp4'\n",
            "file '/tmp/temp_clips/clip_12.mp4'\n",
            "\n",
            "Validating summary video...\n",
            "Summary video created: summary.mp4\n",
            "Summary video created: /content/drive/MyDrive/video_summarizer/summary.mp4\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Define Functions\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "import json\n",
        "\n",
        "from scenedetect import VideoManager, SceneManager, ContentDetector\n",
        "import librosa\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def create_summary_video(video_path, selected_segments, output_path=\"summary.mp4\"):\n",
        "    \"\"\"Create a summarized video by concatenating selected segments.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    temp_dir = \"/tmp/temp_clips\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "    temp_clip_files = []\n",
        "    try:\n",
        "        result = subprocess.run([\"df\", \"-h\", \"/tmp\"], capture_output=True, text=True)\n",
        "        print(f\"Disk space before processing:\\n{result.stdout}\")\n",
        "        print(\"Extracting and re-encoding video clips...\")\n",
        "        for i, (start, end) in enumerate(tqdm(selected_segments, desc=\"Processing clips\")):\n",
        "            temp_clip_path = os.path.join(temp_dir, f\"clip_{i}.mp4\")\n",
        "            cmd = [\n",
        "                \"ffmpeg\", \"-y\", \"-ss\", str(start), \"-i\", video_path,\n",
        "                \"-t\", str(end - start),\n",
        "                \"-c:v\", \"libx264\", \"-preset\", \"ultrafast\", \"-c:a\", \"aac\",\n",
        "                \"-r\", \"25\", \"-s\", \"1920x1080\",\n",
        "                temp_clip_path\n",
        "            ]\n",
        "            with open(\"/tmp/ffmpeg_extract_log.txt\", \"a\") as log_file:\n",
        "                result = subprocess.run(cmd, check=True, stdout=log_file, stderr=log_file)\n",
        "            temp_clip_files.append(temp_clip_path)\n",
        "        print(\"Concatenating clips...\")\n",
        "        concat_list_path = os.path.join(temp_dir, \"concat_list.txt\")\n",
        "        with open(concat_list_path, \"w\") as f:\n",
        "            for clip_path in temp_clip_files:\n",
        "                f.write(f\"file '{os.path.abspath(clip_path)}'\\n\")\n",
        "        with open(concat_list_path, \"r\") as f:\n",
        "            print(f\"Concat list contents:\\n{f.read()}\")\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-y\", \"-f\", \"concat\", \"-safe\", \"0\",\n",
        "            \"-i\", concat_list_path,\n",
        "            \"-c:v\", \"copy\", \"-c:a\", \"copy\",\n",
        "            output_path\n",
        "        ]\n",
        "        with open(\"/tmp/ffmpeg_concat_log.txt\", \"a\") as log_file:\n",
        "            result = subprocess.run(cmd, check=True, stdout=log_file, stderr=log_file)\n",
        "        print(\"Validating summary video...\")\n",
        "        cmd = [\"ffprobe\", \"-v\", \"error\", output_path]\n",
        "        with open(\"/tmp/ffprobe_log.txt\", \"a\") as log_file:\n",
        "            result = subprocess.run(cmd, stdout=log_file, stderr=log_file)\n",
        "            if result.returncode != 0:\n",
        "                raise RuntimeError(f\"Invalid summary video: {output_path}\")\n",
        "        print(f\"Summary video created: {output_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg error: {e}\")\n",
        "        print(\"Check /tmp/ffmpeg_concat_log.txt or /tmp/ffmpeg_extract_log.txt for details\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Error during video creation: {e}\")\n",
        "        print(\"Check /tmp/ffmpeg_extract_log.txt or /tmp/ffprobe_log.txt for details\")\n",
        "        raise\n",
        "    finally:\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "create_summary_video(video_path, selected_segments, output_path=\"summary.mp4\")\n",
        "print(\"Summary video created: /content/drive/MyDrive/video_summarizer/summary.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGH1oXyPZ6QD",
        "outputId": "4f966c2c-6d4a-41b8-86f1-6f7fcc6c2808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response saved to: response.json\n"
          ]
        }
      ],
      "source": [
        "# Cell 10\n",
        "\n",
        "import json\n",
        "def save_response(response, json_path=\"response.json\"):\n",
        "        directory = os.path.dirname(json_path)\n",
        "        if directory:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "        # Save transcript segments to .json\n",
        "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(response, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Response saved to: {json_path}\")\n",
        "\n",
        "\n",
        "response = {\n",
        "            \"link\": url,\n",
        "            \"name\": title,\n",
        "            \"transcript\": transcript,\n",
        "            \"timestamped_summary\": key_points,\n",
        "            \"key_points\": final_summary,\n",
        "            \"summary_video_url\": \"summary/summary.mp4\"\n",
        "        }\n",
        "save_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "mEXARLW2vpq8",
        "outputId": "c23b5dbf-6f14-4d1c-e877-39b57633ae7f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fastapi'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c3c537ce6418>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTPException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddleware\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCORSMiddleware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastapi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#optional\n",
        "\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2x312dojk43C9xrt03Zyh12qSQT_2xMKxpRa1Xii2z7vypy7c\")\n",
        "# Define FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS Middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Allow all for testing; restrict later\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"GET\", \"POST\", \"OPTIONS\"],\n",
        "    allow_headers=[\"Content-Type\", \"Accept\"],\n",
        ")\n",
        "\n",
        "# Request body model\n",
        "class Link(BaseModel):\n",
        "    url: str\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/links/\")\n",
        "async def create_item(link: Link):\n",
        "    try:\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Error processing URL: {str(e)}\")\n",
        "\n",
        "@app.options(\"/links/\")\n",
        "async def options_links():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run FastAPI server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuEp33gtbcEk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b032b1bae0bf4434a33ec1b4996f2b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_640d704fac38475bb8e5e0b9a916d846",
              "IPY_MODEL_78e6eec7244f47f68293bb952e188069",
              "IPY_MODEL_57c58b95b3cf4c81a21359b6216c52fa"
            ],
            "layout": "IPY_MODEL_7e80c782ff874dfbb0e317feac9bd97c"
          }
        },
        "640d704fac38475bb8e5e0b9a916d846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1185be52a9cd4fdaaace3bd360dc20a9",
            "placeholder": "​",
            "style": "IPY_MODEL_f5da46a2817549738cdb3037c77589c9",
            "value": "Transcribing: "
          }
        },
        "78e6eec7244f47f68293bb952e188069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9669f660a7254baa864d3beb9fe92e0b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7fd6b6f6b264846b2b5a77326414554",
            "value": 1
          }
        },
        "57c58b95b3cf4c81a21359b6216c52fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b9722c0dfc4bc299406fa0542dbf71",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f605f0e1654c8d9980beb989e201e8",
            "value": " 1350/? [02:42&lt;00:00,  9.31it/s]"
          }
        },
        "7e80c782ff874dfbb0e317feac9bd97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1185be52a9cd4fdaaace3bd360dc20a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5da46a2817549738cdb3037c77589c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9669f660a7254baa864d3beb9fe92e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f7fd6b6f6b264846b2b5a77326414554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39b9722c0dfc4bc299406fa0542dbf71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f605f0e1654c8d9980beb989e201e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd8d4811cf124cb3bd1c3c4f172f684a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ca7880689546a59f01f3da23e5182b",
              "IPY_MODEL_973c4fa38631442e82a4ee7f1a159402",
              "IPY_MODEL_72c296ef7690413880457982104f8955"
            ],
            "layout": "IPY_MODEL_8285fb93924847b7a1652a3d16ea8a86"
          }
        },
        "62ca7880689546a59f01f3da23e5182b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f03ea51f69ef455ebf67e9a7b12421d9",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a09f817b314681a48ef00919dd7f25",
            "value": "Processing clips: 100%"
          }
        },
        "973c4fa38631442e82a4ee7f1a159402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781788af0cbc4e759ce2e8bca84227ff",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43bb673204bc4cbe8174366b9055faae",
            "value": 13
          }
        },
        "72c296ef7690413880457982104f8955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657883b7b33d4650bd471238b7680e6a",
            "placeholder": "​",
            "style": "IPY_MODEL_e63426d3a969447ab35c424008e3f847",
            "value": " 13/13 [00:27&lt;00:00,  1.64s/it]"
          }
        },
        "8285fb93924847b7a1652a3d16ea8a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03ea51f69ef455ebf67e9a7b12421d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a09f817b314681a48ef00919dd7f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "781788af0cbc4e759ce2e8bca84227ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bb673204bc4cbe8174366b9055faae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "657883b7b33d4650bd471238b7680e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e63426d3a969447ab35c424008e3f847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}